{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSc9iTOk9oxR"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Colab and Kaggle setup\n",
        "# 1) Upload your kaggle.json (from https://www.kaggle.com/<username>/account)\n",
        "#    In Colab: Files pane -> Upload -> select kaggle.json\n",
        "from google.colab import files\n",
        "print(\"Please upload kaggle.json from your Kaggle account page.\")\n",
        "uploaded = files.upload()  # select kaggle.json\n",
        "\n",
        "import os, json, zipfile, shutil\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "with open(\"kaggle.json\", \"r\") as f:\n",
        "    token = json.load(f)\n",
        "\n",
        "# Save credentials\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    json.dump(token, f)\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "# Install Kaggle API\n",
        "!pip -q install kaggle\n",
        "!kaggle --version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Download PlantVillage dataset\n",
        "# Common dataset: \"plantvillage-dataset\" (e.g., crowdAI or variations). If this fails, search in Kaggle Datasets tab.\n",
        "# Example: https://www.kaggle.com/datasets/emmarex/plantdisease\n",
        "# Replace the dataset slug below if you prefer another PlantVillage mirror.\n",
        "\n",
        "DATASET_SLUG = \"emmarex/plantdisease\"  # PlantVillage-like dataset; includes 'PlantVillage' images\n",
        "DATA_DIR = \"/content/data\"\n",
        "ARCHIVE_DIR = \"/content/archive\"\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(ARCHIVE_DIR, exist_ok=True)\n",
        "\n",
        "!kaggle datasets download -d {DATASET_SLUG} -p {ARCHIVE_DIR} --force\n",
        "\n",
        "# Unzip the dataset\n",
        "for fname in os.listdir(ARCHIVE_DIR):\n",
        "    if fname.endswith(\".zip\"):\n",
        "        with zipfile.ZipFile(os.path.join(ARCHIVE_DIR, fname), \"r\") as z:\n",
        "            z.extractall(DATA_DIR)\n",
        "\n",
        "print(\"Data directory contents:\", os.listdir(DATA_DIR))\n"
      ],
      "metadata": {
        "id": "sqrNqOBBDjKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Inspect and normalize directory structure\n",
        "# We will identify the image root containing class-subfolders. Adjust logic based on dataset layout.\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path(DATA_DIR)\n",
        "# Try common subfolder names\n",
        "candidates = [\n",
        "    root / \"PlantVillage\"\n",
        "]\n",
        "img_root = None\n",
        "for c in candidates:\n",
        "    if c.exists() and any(p.is_dir() for p in c.iterdir()):\n",
        "        class_dirs = [p for p in c.iterdir() if p.is_dir()]\n",
        "        # Heuristic: need multiple class folders\n",
        "        if len(class_dirs) >= 2:\n",
        "            img_root = c\n",
        "            break\n",
        "\n",
        "if img_root is None:\n",
        "    raise RuntimeError(\"Could not automatically locate a folder with class subdirectories. Please inspect DATA_DIR and set img_root manually.\")\n",
        "\n",
        "print(\"Using image root:\", img_root)\n",
        "print(\"Found classes:\", [p.name for p in img_root.iterdir() if p.is_dir()])\n"
      ],
      "metadata": {
        "id": "mQ8wzn3dEGu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rsx1x9mvGFvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Optional — programmatic split into train/val/test\n",
        "# If your dataset already has train/val/test folders, skip this and set USE_PROGRAMMATIC_SPLIT=False below.\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "USE_PROGRAMMATIC_SPLIT = True\n",
        "VAL_SPLIT = 0.15\n",
        "TEST_SPLIT = 0.10\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "split_root = Path(\"/content/split\")\n",
        "train_dir = split_root / \"train\"\n",
        "val_dir = split_root / \"val\"\n",
        "test_dir = split_root / \"test\"\n",
        "\n",
        "def safe_copy_tree(src_dir, dst_dir):\n",
        "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for p in src_dir.iterdir():\n",
        "        if p.is_dir():\n",
        "            (dst_dir / p.name).mkdir(exist_ok=True)\n",
        "\n",
        "if USE_PROGRAMMATIC_SPLIT:\n",
        "    # Collect files by class\n",
        "    classes = [p for p in img_root.iterdir() if p.is_dir()]\n",
        "    for cls in classes:\n",
        "        images = [p for p in cls.rglob(\"*\") if p.is_file() and p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]]\n",
        "        random.shuffle(images)\n",
        "        n = len(images)\n",
        "        n_val = int(n * VAL_SPLIT)\n",
        "        n_test = int(n * TEST_SPLIT)\n",
        "        n_train = n - n_val - n_test\n",
        "\n",
        "        splits = {\n",
        "            train_dir / cls.name: images[:n_train],\n",
        "            val_dir / cls.name: images[n_train:n_train+n_val],\n",
        "            test_dir / cls.name: images[n_train+n_val:],\n",
        "        }\n",
        "        for out_dir, files_ in splits.items():\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            for f in files_:\n",
        "                # Avoid name collisions by including class name\n",
        "                dest = out_dir / f.name\n",
        "                # If collision, prefix with an index\n",
        "                i = 1\n",
        "                while dest.exists():\n",
        "                    dest = out_dir / f\"{i}_{f.name}\"\n",
        "                    i += 1\n",
        "                shutil.copy2(f, dest)\n",
        "\n",
        "print(\"Split dirs created:\",\n",
        "      train_dir.exists(), val_dir.exists(), test_dir.exists())\n"
      ],
      "metadata": {
        "id": "FTJHo053EWdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Imports and device\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "import time, copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "3HKGFjtEEktU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Transforms and datasets\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2  # Colab default: 2 is safe\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "eval_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# Choose source dirs depending on split\n",
        "if USE_PROGRAMMATIC_SPLIT:\n",
        "    train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
        "    val_dataset   = datasets.ImageFolder(root=val_dir, transform=eval_transforms)\n",
        "    test_dataset  = datasets.ImageFolder(root=test_dir, transform=eval_transforms)\n",
        "else:\n",
        "    # If the dataset already had train/val/test\n",
        "    pre_split_root = img_root  # adjust if different\n",
        "    train_dataset = datasets.ImageFolder(root=pre_split_root / \"train\", transform=train_transforms)\n",
        "    val_dataset   = datasets.ImageFolder(root=pre_split_root / \"val\", transform=eval_transforms)\n",
        "    test_dataset  = datasets.ImageFolder(root=pre_split_root / \"test\", transform=eval_transforms)\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "class_to_idx = train_dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print(\"Classes:\", train_dataset.classes)\n",
        "print(\"Dataset sizes — Train:\", len(train_dataset), \"Val:\", len(val_dataset), \"Test:\", len(test_dataset))\n"
      ],
      "metadata": {
        "id": "yKbfj1R_EzRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Build ResNet50 and optimizer\n",
        "# Use pretrained weights; modify final FC layer to match num_classes\n",
        "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "in_features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "# Option: freeze backbone for quick baseline\n",
        "FREEZE_BACKBONE = False\n",
        "if FREEZE_BACKBONE:\n",
        "    for name, p in resnet50.named_parameters():\n",
        "        if not name.startswith(\"fc\"):\n",
        "            p.requires_grad = False\n",
        "\n",
        "resnet50 = resnet50.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, resnet50.parameters()),\n",
        "                        lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "EPOCHS = 15\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n"
      ],
      "metadata": {
        "id": "vQ1e1u68G3Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Training and validation loops\n",
        "def train_one_epoch(model, loader, optimizer, criterion, scaler):\n",
        "    model.train()\n",
        "    running_loss, running_corrects, total = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs = inputs.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += (preds == labels).sum().item()\n",
        "        total += inputs.size(0)\n",
        "\n",
        "    return running_loss / total, running_corrects / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, running_corrects, total = 0.0, 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs = inputs.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += (preds == labels).sum().item()\n",
        "        total += inputs.size(0)\n",
        "\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "    return running_loss / total, running_corrects / total, torch.cat(all_preds).numpy(), torch.cat(all_labels).numpy()\n"
      ],
      "metadata": {
        "id": "YNkZI9tnHKLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Current device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
      ],
      "metadata": {
        "id": "b-p7fNqhIoQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Run training\n",
        "\n",
        "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "best_acc = 0.0\n",
        "best_wts = copy.deepcopy(resnet50.state_dict())\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_one_epoch(resnet50, train_loader, optimizer, criterion, scaler)\n",
        "    val_loss, val_acc, _, _ = evaluate(resnet50, val_loader, criterion)\n",
        "    scheduler.step()\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_wts = copy.deepcopy(resnet50.state_dict())\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | Train {train_acc:.4f} loss {train_loss:.4f} | Val {val_acc:.4f} loss {val_loss:.4f}\")\n",
        "\n",
        "elapsed = (time.time() - start) / 60\n",
        "print(f\"Training complete in {elapsed:.1f} min. Best Val Acc: {best_acc:.4f}\")\n",
        "\n",
        "resnet50.load_state_dict(best_wts)\n"
      ],
      "metadata": {
        "id": "Wa2W5_Z-HUiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Plot curves\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axs[0].plot(history[\"train_loss\"], label=\"Train\")\n",
        "axs[0].plot(history[\"val_loss\"], label=\"Val\")\n",
        "axs[0].set_title(\"Loss\")\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(history[\"train_acc\"], label=\"Train\")\n",
        "axs[1].plot(history[\"val_acc\"], label=\"Val\")\n",
        "axs[1].set_title(\"Accuracy\")\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "miKllsL2L_IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Test set evaluation\n",
        "test_loss, test_acc, test_preds, test_labels = evaluate(resnet50, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "target_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
        "print(classification_report(test_labels, test_preds, target_names=target_names))\n",
        "\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1yUBR_6KMICU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "SAVE_DIR = Path(\"/content/artifacts\")\n",
        "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODEL_PATH = SAVE_DIR / \"resnet50_plantvillage_checkpoint.pth\"\n",
        "\n",
        "checkpoint = {\n",
        "    \"model_state_dict\": resnet50.state_dict(),\n",
        "    \"class_to_idx\": class_to_idx,\n",
        "    \"idx_to_class\": {v: k for k, v in class_to_idx.items()},\n",
        "    \"arch\": \"resnet50\"\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, MODEL_PATH)\n",
        "\n",
        "print(\"Saved full checkpoint to:\", MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "WJA_hKGyMgnR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}