{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d776d5",
   "metadata": {},
   "source": [
    "\n",
    "# üåø PlantDocBot ‚Äì Unified Training Notebook (Google Colab)\n",
    "\n",
    "This notebook **combines all previous Colab files into ONE clean, executable pipeline**:\n",
    "- Dataset loading\n",
    "- Model creation\n",
    "- Training with class weights\n",
    "- Validation\n",
    "- Model saving for Streamlit app\n",
    "\n",
    "Run cells **top to bottom**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 1Ô∏è‚É£ Imports & Setup\n",
    "# =====================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd66e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 2Ô∏è‚É£ Device Configuration\n",
    "# =====================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 3Ô∏è‚É£ Dataset Paths\n",
    "# =====================\n",
    "# Update this path if needed\n",
    "DATA_DIR = \"/content/dataset\"\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "val_dir = os.path.join(DATA_DIR, \"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45bf5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 4Ô∏è‚É£ Image Transforms\n",
    "# =====================\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a49f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 5Ô∏è‚É£ Load Dataset\n",
    "# =====================\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_data = datasets.ImageFolder(val_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(train_data.classes)\n",
    "print(\"Classes:\", train_data.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7646693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 6Ô∏è‚É£ Class Weights (Imbalance Handling)\n",
    "# =====================\n",
    "counts = Counter(train_data.targets)\n",
    "total = sum(counts.values())\n",
    "\n",
    "class_weights = [total / counts[i] for i in range(num_classes)]\n",
    "weights = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ea39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 7Ô∏è‚É£ Model Setup (ResNet50)\n",
    "# =====================\n",
    "model = models.resnet50(weights=None)\n",
    "model.fc = nn.Linear(2048, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 8Ô∏è‚É£ Training Loop\n",
    "# =====================\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Loss: {train_loss:.2f} | Val Acc: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4609568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# 9Ô∏è‚É£ Save Model for Streamlit App\n",
    "# =====================\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"class_names\": train_data.classes\n",
    "}, \"models/plant_disease_resnet50.pth\")\n",
    "\n",
    "print(\"‚úÖ Model saved as models/plant_disease_resnet50.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d842d",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Done!\n",
    "You can now:\n",
    "- Download `plant_disease_resnet50.pth`\n",
    "- Place it inside your **Streamlit `models/` folder**\n",
    "- Run `streamlit run app.py`\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
