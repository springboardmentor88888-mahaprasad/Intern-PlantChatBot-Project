# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nvRC_A-8gOb0vjx6r-43tSZu_H-eEMwM
"""

from google.colab import drive
drive.mount('/content/drive')

BASE_DIR = '/content/drive/MyDrive/PlantBot'

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle* ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d emmarex/plantdisease -p /content

!unzip -q /content/plantdisease.zip -d /content/plantvillage_data

!ls /content/plantvillage_data/plantvillage/PlantVillage | head

import os, shutil, random
from glob import glob

src_root = "/content/plantvillage_data/plantvillage/PlantVillage"
dst_root = "/content/plantvillage_split"

train_dir = os.path.join(dst_root, "train")
val_dir = os.path.join(dst_root, "val")

os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

classes = os.listdir(src_root)
split_ratio = 0.8  # 80% train / 20% val

for cls in classes:
    src_cls = os.path.join(src_root, cls)
    images = glob(os.path.join(src_cls, "*.jpg"))

    random.shuffle(images)
    split = int(len(images) * split_ratio)

    train_imgs = images[:split]
    val_imgs = images[split:]

    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)
    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)

    for img in train_imgs:
        shutil.copy(img, os.path.join(train_dir, cls))

    for img in val_imgs:
        shutil.copy(img, os.path.join(val_dir, cls))

print("✔ Train/val split completed successfully!")

!ls /content/plantvillage_split/train | head

!ls /content/plantvillage_split/val | head

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

train_dir = "/content/plantvillage_split/train"
val_dir = "/content/plantvillage_split/val"

train_tfms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
])

val_tfms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

train_data = datasets.ImageFolder(train_dir, transform=train_tfms)
val_data = datasets.ImageFolder(val_dir, transform=val_tfms)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32, shuffle=False)

num_classes = len(train_data.classes)
print("Number of disease classes:", num_classes)

model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

!find /content/plantvillage_split/train -type f | head

import os

root = "/content/plantvillage_split/train"

for folder in os.listdir(root):
    old = os.path.join(root, folder)
    new = os.path.join(root, folder.lower())
    if old != new:
        os.rename(old, new)

root = "/content/plantvillage_split/val"

for folder in os.listdir(root):
    old = os.path.join(root, folder)
    new = os.path.join(root, folder.lower())
    if old != new:
        os.rename(old, new)

!ls /content/plantvillage_split/train

import os

train_path = "/content/plantvillage_split/train"
val_path = "/content/plantvillage_split/val"

def clean_names(path):
    for folder in os.listdir(path):
        old = os.path.join(path, folder)
        clean = folder.replace("__", "_")  # fix double underscores
        clean = clean.lower().strip()      # enforce lowercase
        new = os.path.join(path, clean)

        if old != new:
            print("RENAMING:", old, "→", new)
            os.rename(old, new)

clean_names(train_path)
clean_names(val_path)

!ls /content/plantvillage_split/train

import os
import re

root_paths = [
    "/content/plantvillage_split/train",
    "/content/plantvillage_split/val"
]

def clean_name(name):
    name = name.lower()                     # lowercase
    name = re.sub(r'_+', '_', name)         # replace multiple underscores with 1
    name = name.strip('_')                  # remove leading/trailing underscore
    return name

for root in root_paths:
    for folder in os.listdir(root):
        old = os.path.join(root, folder)
        new_name = clean_name(folder)
        new = os.path.join(root, new_name)

        if old != new:
            print("RENAMING:", folder, "--->", new_name)
            os.rename(old, new)

!ls /content/plantvillage_split/train

!ls -1 /content/plantvillage_split/train

!ls -1 /content/plantvillage_split/train

!find /content -type d -name "pepper_bell_bacterial_spot"

train_dir = "THE_REAL_PATH_FROM_OUTPUT"
val_dir   = "THE_REAL_PATH_FROM_OUTPUT/../val"

!find /content -type d -name "pepper_bell_bacterial_spot"

!find /content/plantvillage_split/train -type f | wc -l

!tree /content/plantvillage_split/train | head -n 50

!ls -R /content/plantvillage_split/train | head -n 50

!ls /content

!ls ~/.kaggle

!rm -rf /content/plantvillage_split

!ls /content

!kaggle datasets download -d emmarex/plantdisease -p /content

!ls /content

!unzip -o /content/plantdisease.zip -d /content/plantvillage_raw

!ls /content/plantvillage_raw

!ls /content/plantvillage_raw/plantvillage/PlantVillage | head

!pip install split-folders

import splitfolders

splitfolders.ratio(
    "/content/plantvillage_raw/plantvillage/PlantVillage",
    output="/content/plantvillage_split",
    seed=42,
    ratio=(.8, .2)
)

!find /content/plantvillage_split/train -type f | wc -l

!find /content/plantvillage_split/val -type f | wc -l

train_dir = "/content/plantvillage_split/train"
val_dir   = "/content/plantvillage_split/val"

train_data = datasets.ImageFolder(train_dir, transform=train_tfms)
val_data   = datasets.ImageFolder(val_dir, transform=val_tfms)

print("Train images:", len(train_data))
print("Val images:", len(val_data))
print("Classes:", train_data.classes)

from torch.utils.data import DataLoader

batch_size = 32

train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader   = DataLoader(val_data, batch_size=batch_size)

len(train_loader), len(val_loader)